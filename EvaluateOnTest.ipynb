{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EvaluateOnTest.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMZ/PX7mbPJEgCtMp1Bj+1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nKhqdELfQKbI","executionInfo":{"status":"ok","timestamp":1642792938113,"user_tz":-120,"elapsed":5289,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"7ad173d3-cc86-4ac9-963b-3b2dc84f91e8"},"source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)\n","%cd ./drive/My Drive/Narrator Disambiguation"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/Narrator Disambiguation\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlW8MPGzQUw_","executionInfo":{"status":"ok","timestamp":1642792946138,"user_tz":-120,"elapsed":8052,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"5a675a2d-80fa-4163-a2c3-4a73792448a1"},"source":["!pip install farasapy\n","!pip install pyarabic\n","!git clone https://github.com/aub-mind/arabert\n","!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: farasapy in /usr/local/lib/python3.7/dist-packages (0.0.14)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n","Requirement already satisfied: pyarabic in /usr/local/lib/python3.7/dist-packages (0.6.14)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n","fatal: destination path 'arabert' already exists and is not an empty directory.\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]},{"cell_type":"code","metadata":{"id":"5w95yrdCQaSO","executionInfo":{"status":"ok","timestamp":1642792947707,"user_tz":-120,"elapsed":1644,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["import torch\n","import math\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import torch.optim as optim\n","import sys"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQ77z8QsQbyQ","executionInfo":{"status":"ok","timestamp":1642792947709,"user_tz":-120,"elapsed":26,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["from transformers import BertTokenizer, BertModel, BertConfig\n","from arabert.preprocess import ArabertPreprocessor"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHFrSwuTQeAT","executionInfo":{"status":"ok","timestamp":1642792947712,"user_tz":-120,"elapsed":22,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["device = torch.device(\"cuda\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGVNsuJqQnrE","executionInfo":{"status":"ok","timestamp":1642792948411,"user_tz":-120,"elapsed":716,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["f = open('Large dataset/sanads.test', 'r')\n","sanads = f.readlines()\n","f.close()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"2wOiQXCnRohY","executionInfo":{"status":"ok","timestamp":1642792948413,"user_tz":-120,"elapsed":31,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["# Load labels\n","f = open('Large dataset/labels.test', 'r')\n","lines = f.readlines()\n","labels_no_padding = list(map(lambda x: list(map(int,x.split(','))), lines))\n","f.close()\n","\n","labels_flat = [l for labels_ls in labels_no_padding for l in labels_ls]\n","\n","# Pad labels\n","padding_label = 18298\n","labels = [li+[padding_label]*(10-len(li)) for li in labels_no_padding]\n","labels = torch.tensor(labels)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f12OlAmgQyur","executionInfo":{"status":"ok","timestamp":1642792948415,"user_tz":-120,"elapsed":32,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"00846d98-11f0-4268-ccf2-ec7efb77202f"},"source":["n_sanads = len(sanads)\n","max_l=300\n","emb_size = 768\n","n_categories = 18299\n","print(n_sanads)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["27056\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Faqocq-Q-3I","executionInfo":{"status":"ok","timestamp":1642792961422,"user_tz":-120,"elapsed":13026,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"0ccbdeac-f369-4165-ade3-0a5eab50a8b7"},"source":["arabert_prep = ArabertPreprocessor(model_name='bert-base-arabertv2')\n","tokenizer = BertTokenizer.from_pretrained('aubmindlab/bert-base-arabertv2')\n","model = BertModel.from_pretrained('aubmindlab/bert-base-arabertv2',output_hidden_states=True)\n","model.eval()\n","model.to(device)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[2022-01-21 19:22:31,430 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(64000, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# **Frozen AraBERT**"],"metadata":{"id":"ZXOBzUW4lWke"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ge7NYVgWRDd1","executionInfo":{"status":"ok","timestamp":1642793204030,"user_tz":-120,"elapsed":242739,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"f062cb49-32b7-45d4-8e16-56db41546e1d"},"source":["# Calculate contextual embeddings for each name in the training sanads\n","\n","names_embed = []\n","c=0\n","for s in sanads:\n","  if c % 1000 == 0:\n","    print(\"Finished \", c)\n","  \n","  c+=1\n","\n","  # Preprocessing and Tokenization\n","  sanad_prep = arabert_prep.preprocess(s)\n","  sanad_wrapped = tokenizer.cls_token + sanad_prep + tokenizer.sep_token\n","  tokens = tokenizer.tokenize(sanad_wrapped)\n","  indexed_tokens = torch.LongTensor([tokenizer.convert_tokens_to_ids(tokens)]).to(device)\n","\n","  # Run sanad through model\n","  with torch.no_grad(): \n","    outputs = model(indexed_tokens)\n","    embs = outputs[2][-1][0]\n","  \n","  # Calculate start index of each name in the sanad\n","  # names are sparated by the word فاصل\n","  indices = [i for i, x in enumerate(tokens) if x == 'فاصل' and (tokens[i+1][0] != '+') and (tokens[i+1][0] != '#')]\n","\n","  name_embs = torch.tensor([]).to(device)\n","  l=1\n","  for i,t in enumerate(tokens):\n","    if i == 0 or i == len(tokens) - 1:\n","      continue\n","    if i in indices:\n","      names_embed += [torch.mean(name_embs,0)]\n","      name_embs = torch.tensor([]).to(device)\n","      l=1\n","\n","    # Tokens that has + in it are prefixes that are not included\n","    elif '+' not in t:\n","      # For OOV average the embeddings of the word parts\n","      if t.startswith('##'):\n","        if len(name_embs) != 0:\n","          name_embs[-1] += embs[i]\n","        else:\n","          name_embs = torch.cat((name_embs,embs[i].unsqueeze(0)),0)\n","\n","        l+=1\n","      else:\n","        if l > 1:\n","          name_embs[-1] /= l\n","          l = 1\n","        name_embs = torch.cat((name_embs,embs[i].unsqueeze(0)),0)\n","\n","  names_embed += [torch.mean(name_embs,0)]\n","    \n","\n","print(len(names_embed))\n","print(len(names_embed[0]))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Finished  0\n","Finished  1000\n","Finished  2000\n","Finished  3000\n","Finished  4000\n","Finished  5000\n","Finished  6000\n","Finished  7000\n","Finished  8000\n","Finished  9000\n","Finished  10000\n","Finished  11000\n","Finished  12000\n","Finished  13000\n","Finished  14000\n","Finished  15000\n","Finished  16000\n","Finished  17000\n","Finished  18000\n","Finished  19000\n","Finished  20000\n","Finished  21000\n","Finished  22000\n","Finished  23000\n","Finished  24000\n","Finished  25000\n","Finished  26000\n","Finished  27000\n","150904\n","768\n"]}]},{"cell_type":"code","metadata":{"id":"C-XPwlJ_SUD2","executionInfo":{"status":"ok","timestamp":1642793204031,"user_tz":-120,"elapsed":46,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["def batch_iter(names, labels, batch_size, shuffle=True):\n","    \n","    data_len = len(names)\n","   \n","    batch_num = math.ceil(data_len / batch_size)\n","    index_array = list(range(data_len))\n","\n","    if shuffle:\n","        np.random.shuffle(index_array)\n","\n","    for i in range(batch_num):\n","        indices = index_array[i * batch_size: (i + 1) * batch_size]\n","        names_b = torch.stack([names[idx] for idx in indices])\n","        labels_b = torch.tensor([labels[idx] for idx in indices])\n","        \n","        yield names_b.to(device), labels_b.to(device)\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoKmOawjSYfG","executionInfo":{"status":"ok","timestamp":1642793204031,"user_tz":-120,"elapsed":20,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"0a59332d-9856-4a77-b600-1cbf40f8f56d"},"source":["model_save_path = 'Models/frozen-AraBERT-large.bin'\n","classifier = nn.Linear(emb_size, n_categories)\n","classifier.to(device)\n","classifier.load_state_dict(torch.load(model_save_path, map_location=torch.device(device)))"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"_qq8bqa7SsSU","executionInfo":{"status":"ok","timestamp":1642793204032,"user_tz":-120,"elapsed":13,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["from sklearn.metrics import f1_score\n","\n","def get_f1(model, X, y):\n","  b_size = 500\n","\n","  \n","  target = []\n","  predicted = []\n","  for xs, ts in batch_iter(X, y, b_size, shuffle=False):\n","\n","    zs = model(xs)\n","    pred = zs.max(1, keepdim=True)[1].view_as(ts)\n","    target += ts.tolist()\n","    predicted += pred.tolist()\n","\n","  score1 = f1_score(target, predicted, average='micro')\n","  score2 = f1_score(target, predicted, average='macro')\n","  \n","  return score1,score2"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tbhpDJDWm09","executionInfo":{"status":"ok","timestamp":1642793205803,"user_tz":-120,"elapsed":1782,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"67412e34-1880-4582-de94-30fb5d82b5a5"},"source":["get_f1(classifier, names_embed, labels_flat)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.7752876000636166, 0.6800067932157435)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"-9MDGfjtaLE1","executionInfo":{"status":"ok","timestamp":1642793205805,"user_tz":-120,"elapsed":10,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["def get_SER(model, X, y):\n","  correct, total = 0, len(y)\n","  \n","  i = 0\n","  for labels in y:\n","    xs = []\n","    ts = []\n","\n","    for l in labels:\n","      ts += [l]\n","      xs += [X[i]]\n","      i+=1\n","      if i % 2000 == 0:\n","        print(i)\n","\n","    xs = torch.stack(xs)\n","    ts = torch.tensor(ts, device=device)\n","    zs = model(xs)\n","    pred = zs.max(1, keepdim=True)[1] \n","    \n","    correct += pred.eq(ts.view_as(pred)).prod().item()\n","    \n","  return 100 - 100*(correct / total)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UI9NVRfaQIC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642793213240,"user_tz":-120,"elapsed":7443,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"4bad114a-0647-4e8e-d10c-321d87d0a36d"},"source":["get_SER(classifier, names_embed, labels_no_padding)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2000\n","4000\n","6000\n","8000\n","10000\n","12000\n","14000\n","16000\n","18000\n","20000\n","22000\n","24000\n","26000\n","28000\n","30000\n","32000\n","34000\n","36000\n","38000\n","40000\n","42000\n","44000\n","46000\n","48000\n","50000\n","52000\n","54000\n","56000\n","58000\n","60000\n","62000\n","64000\n","66000\n","68000\n","70000\n","72000\n","74000\n","76000\n","78000\n","80000\n","82000\n","84000\n","86000\n","88000\n","90000\n","92000\n","94000\n","96000\n","98000\n","100000\n","102000\n","104000\n","106000\n","108000\n","110000\n","112000\n","114000\n","116000\n","118000\n","120000\n","122000\n","124000\n","126000\n","128000\n","130000\n","132000\n","134000\n","136000\n","138000\n","140000\n","142000\n","144000\n","146000\n","148000\n","150000\n"]},{"output_type":"execute_result","data":{"text/plain":["73.44766410408042"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"eody-uymX6uT"},"source":["# **Tuned**"]},{"cell_type":"code","metadata":{"id":"etKpitC8X6Mn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642793261546,"user_tz":-120,"elapsed":48336,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"5c2aceab-09f6-41d7-fc69-2747cdddc5a2"},"source":["# Preprocessing\n","indexed_tokens = torch.zeros((n_sanads,max_l), dtype=torch.long)\n","attention_mask = torch.zeros((n_sanads,max_l), dtype=torch.long)\n","\n","an_indices = []\n","\n","padding_token = tokenizer.pad_token\n","co=0\n","for s_num in range(n_sanads):\n","\n","  co+=1\n","  if co % 1000 == 0:\n","    print(co)\n","\n","  \n","  sanad_connected = arabert_prep.preprocess(sanads[s_num])\n","  \n","  sanad_wrapped = tokenizer.cls_token + sanad_connected + tokenizer.sep_token\n","\n","  tokenized_text = tokenizer.tokenize(sanad_wrapped)\n","  tokenized_text_padded = tokenized_text+[padding_token]*(max_l-len(tokenized_text))\n","  indices = [i for i, x in enumerate(tokenized_text) if x == \"فاصل\" and (tokenized_text[i+1][0] != '+')] + [len(tokenized_text)]\n","  \n","  an_indices += [indices]\n","  \n","  indexed_tokens[s_num] = torch.LongTensor(tokenizer.convert_tokens_to_ids(tokenized_text_padded))\n","  attention_mask[s_num] = torch.cat((torch.ones((len(tokenized_text))),torch.zeros((len(tokenized_text_padded)-len(tokenized_text)))))\n"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYXam2qRW08g","executionInfo":{"status":"ok","timestamp":1642793261548,"user_tz":-120,"elapsed":81,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"9b194f77-7ff4-4c39-9f4d-6a7d01ac1c11"},"source":["# Calculate lengths of names in the sanads\n","names_lens = []\n","for idxs in an_indices:\n","  idx_len = len(idxs)\n","  names_lens += [[idxs[0]] + [idxs[i+1]-idxs[i]-1 for i in range(idx_len-1)] + [1 for j in range(10 - idx_len)]]\n","\n","names_lens = torch.tensor(names_lens)\n","print(names_lens.shape)\n"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([27056, 10])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qESu_mG2YZ49","executionInfo":{"status":"ok","timestamp":1642793271154,"user_tz":-120,"elapsed":9627,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"478bfca0-5e35-4507-ee44-ee920575424a"},"source":["# Generate masks to extract names from sanads\n","mask_tensor = torch.tensor([\n","         [[0] + [1]*(indices[0]-1) + [0]*(max_l-indices[0])] +\n","         [[0]*indices[i] + [1]*(indices[i+1]-indices[i]) + [0]*(max_l-indices[i+1]) for i in range(len(indices)-2)] +\n","         [[0]*indices[-2] + [1]*(indices[-1]-indices[-2]) + [0]*(max_l-indices[-1]-1) + [0]] +\n","         [[0]*max_l for j in range(10 -len(indices))]\n","         \n"," for indices in an_indices]).unsqueeze(-1)\n","\n","print(mask_tensor.shape)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([27056, 10, 300, 1])\n"]}]},{"cell_type":"code","metadata":{"id":"pkEn7rnpYxaW","executionInfo":{"status":"ok","timestamp":1642793271156,"user_tz":-120,"elapsed":130,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["def batch_iter(token_ids, attention_mask, names_masks, names_lens, labels, batch_size, shuffle=True):\n","    \n","    data_len = token_ids.shape[0]\n","    batch_num = math.ceil(data_len / batch_size)\n","    index_array = list(range(data_len))\n","\n","    if shuffle:\n","        np.random.shuffle(index_array)\n","\n","    for i in range(batch_num):\n","        indices = index_array[i * batch_size: (i + 1) * batch_size]\n","\n","        token_ids_b = torch.cat([token_ids[idx].unsqueeze(0) for idx in indices])\n","        attention_mask_b = torch.cat([attention_mask[idx].unsqueeze(0) for idx in indices])\n","        names_masks_b = torch.cat([names_masks[idx].unsqueeze(0) for idx in indices])\n","        names_lens_b = torch.cat([names_lens[idx].unsqueeze(0) for idx in indices])\n","        labels_b = torch.cat([labels[idx].unsqueeze(0) for idx in indices])\n","\n","        \n","        \n","        yield token_ids_b.to(device),attention_mask_b.to(device),names_masks_b.to(device),names_lens_b.to(device),labels_b.to(device)\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"OGAqBRYZY3SM","executionInfo":{"status":"ok","timestamp":1642793271165,"user_tz":-120,"elapsed":132,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["# Model\n","\n","class ClassifyNarrator(nn.Module):\n","    def __init__(self, emb_size, output_size, max_l):\n","       \n","        super(ClassifyNarrator, self).__init__()\n","\n","        self.max_l = max_l\n","        self.emb_size = emb_size\n","\n","        self.bert = BertModel.from_pretrained('aubmindlab/bert-base-arabertv2',output_hidden_states=True)\n","        self.i2o = nn.Linear(emb_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","        \n","    def forward(self, tokens_tensor, attention_mask, names_masks, names_lens):\n","       \n","        batch_size = tokens_tensor.shape[0]\n","\n","        brt_outputs = self.bert(tokens_tensor, attention_mask=attention_mask)\n","        embs = brt_outputs[2][-1]\n","\n","        names_emb = torch.mul(embs.unsqueeze(1), names_masks).view(batch_size*10,self.max_l,self.emb_size)\n","\n","        emb_sum = torch.sum(names_emb,1)\n","        emb_avg = torch.div(emb_sum, names_lens.view(batch_size*10,1))\n","\n","        output = self.i2o(emb_avg) \n","        \n","        output = self.softmax(output)        \n","\n","        return output\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3ITalsbY9ej","executionInfo":{"status":"ok","timestamp":1642793275106,"user_tz":-120,"elapsed":4069,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"c102b298-ef6c-4177-f006-077b0b48dfed"},"source":["classifier = ClassifyNarrator(emb_size, n_categories, max_l)\n","classifier.to(device)\n","model_save_path = 'Models/tuned-AraBERT-large.bin'\n","classifier.load_state_dict(torch.load(model_save_path, map_location=torch.device(device)))"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"OWY_jOW6ZKFv","executionInfo":{"status":"ok","timestamp":1642793275108,"user_tz":-120,"elapsed":14,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["from sklearn.metrics import f1_score\n","\n","def get_f1(model, token_ids, attention_mask, names_masks,names_lens, y):\n","\n","  was_training = model.training\n","  model.eval()\n","\n","  b_size = 400\n","\n","  target = []\n","  predicted = []\n","\n","  with torch.no_grad():\n","    for token_ids_b, attention_mask_b, names_masks_b,names_lens_b, ts in batch_iter(token_ids,\n","                                                                       attention_mask,\n","                                                                       names_masks,\n","                                                                       names_lens,\n","                                                                       y,\n","                                                                       b_size):\n","\n","      zs = model(token_ids_b, attention_mask_b, names_masks_b, names_lens_b)\n","      pred = zs.max(1, keepdim=True)[1].view((len(ts)*10))\n","      ts = ts.view((len(ts)*10))\n","\n","      \n","      target += ts[ts!=padding_label].tolist()\n","      predicted += pred[ts!=padding_label].tolist()\n","\n","  score1 = f1_score(target, predicted, average='micro')\n","  score2 = f1_score(target, predicted, average='macro')\n","\n","  if was_training:\n","    model.train()\n","  \n","  return score1,score2"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD5eCne3ZMqq","executionInfo":{"status":"ok","timestamp":1642793534965,"user_tz":-120,"elapsed":259868,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"0bee4ab4-10b2-421c-a49a-22ec12d9eb9c"},"source":["get_f1(classifier,indexed_tokens,attention_mask,mask_tensor,names_lens,labels)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.835471558076658, 0.7884138044909654)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"VdVxQmjNZsVU","executionInfo":{"status":"ok","timestamp":1642793534968,"user_tz":-120,"elapsed":20,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":["def get_accuracy(model, token_ids, attention_mask, names_masks,names_lens, y):\n","  was_training = model.training\n","  model.eval()\n","\n","  b_size = 400\n","\n","  correct, total = 0, len(y)\n","  with torch.no_grad():\n","      for token_ids_b, attention_mask_b, names_masks_b,names_lens_b, ts in batch_iter(token_ids,\n","                                                                       attention_mask,\n","                                                                       names_masks,\n","                                                                       names_lens,\n","                                                                       y,\n","                                                                       b_size,\n","                                                                       shuffle=False):\n","\n","        zs = model(token_ids_b, attention_mask_b, names_masks_b, names_lens_b)\n","        pred = zs.max(1, keepdim=True)[1].view(-1,10) \n","        \n","        correct += torch.logical_or(pred.eq(ts) , ts==padding_label).prod(1).sum().item()\n","        \n","  if was_training:\n","    model.train()\n","\n","  return 100 - 100*(correct / total)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wq8YPWKZuvg","executionInfo":{"status":"ok","timestamp":1642793794590,"user_tz":-120,"elapsed":259638,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}},"outputId":"35847f42-432d-43d8-961f-6a04dd288136"},"source":["get_accuracy(classifier,indexed_tokens,attention_mask,mask_tensor,names_lens,labels)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["60.603932584269664"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"-F0uyJo1boBa","executionInfo":{"status":"ok","timestamp":1642793794596,"user_tz":-120,"elapsed":63,"user":{"displayName":"Somaia Mahmoud","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04857189607279793254"}}},"source":[""],"execution_count":26,"outputs":[]}]}